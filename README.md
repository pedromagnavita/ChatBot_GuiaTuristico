# Chatbot Guia Tur√≠stico Offline com RAG e LLM Local

Este projeto implementa um chatbot de linha de comando que funciona como um guia tur√≠stico inteligente e totalmente offline. Ele utiliza um Large Language Model (LLM) rodando localmente e a t√©cnica de Gera√ß√£o Aumentada por Recupera√ß√£o (RAG) para responder perguntas com base em um documento de texto espec√≠fico (por exemplo, um guia sobre Machu Picchu).

O principal objetivo √© fornecer acesso a informa√ß√µes detalhadas em locais remotos onde o acesso √† internet √© inexistente ou pouco confi√°vel.

## ‚ú® Funcionalidades

  - **Totalmente Offline:** N√£o requer conex√£o com a internet para funcionar.
  - **LLM Local:** Utiliza o [Ollama](https://ollama.com/) para rodar modelos de linguagem como o Llama 3 diretamente na sua m√°quina.
  - **Base de Conhecimento Customiz√°vel:** Responde perguntas com base no conte√∫do de um arquivo de texto que voc√™ fornece.
  - **Mem√≥ria Conversacional:** Mant√©m o contexto das √∫ltimas intera√ß√µes para permitir perguntas de acompanhamento.

## ‚öôÔ∏è Arquitetura

O projeto √© dividido em dois scripts principais:

1.  **`index.py`**: Este √© o script de indexa√ß√£o. Ele l√™ o arquivo de texto (`machu-picchu-guide.txt`), o divide em peda√ßos, gera os embeddings (vetores num√©ricos) usando um modelo da Hugging Face e salva o √≠ndice vetorial no disco usando FAISS. **Este script √© executado apenas uma vez** ou sempre que o documento guia for atualizado.

2.  **`main.py`**: Esta √© a aplica√ß√£o principal do chatbot. Ele carrega o LLM via Ollama e o √≠ndice vetorial FAISS j√° pr√©-processado. Ele gerencia a intera√ß√£o com o usu√°rio, busca informa√ß√µes relevantes no √≠ndice e usa o LLM para gerar respostas contextuais.

## üöÄ Como Usar

Siga os passos abaixo para configurar e executar o projeto.

### 1\. Pr√©-requisitos

  - [Python](https://www.python.org/downloads/) 3.8 ou superior.
  - [Ollama](https://ollama.com/) instalado e rodando.
  - [Git](https://git-scm.com/) para clonar o reposit√≥rio.

### 2\. Instala√ß√£o

Primeiro, clone o reposit√≥rio e navegue para a pasta do projeto.

```bash
git clone <url-do-seu-repositorio>
cd <nome-da-pasta-do-projeto>
```

√â altamente recomendado criar um ambiente virtual para isolar as depend√™ncias do projeto.

```bash
# Criar o ambiente virtual
python -m venv .venv

# Ativar o ambiente virtual
# No Windows:
.venv\Scripts\activate
# No macOS/Linux:
source .venv/bin/activate
```

Instale as depend√™ncias do `requirements.txt`:

```bash
pip install -r requirements.txt
```

### 3\. Configura√ß√£o dos Modelos (Ollama)

Baixe o modelo atrav√©s do Ollama. Abra seu terminal e execute:

```bash
# Modelo de Linguagem Principal (LLM)
ollama pull llama3:8b-instruct-q4_0
# Voc√™ pode esolher seu modelo, desde que o renomeie no c√≥digo "LLM_MODEL =..." 
```

### 4\. Preparando o Conte√∫do

1.  Crie um arquivo de texto na raiz do projeto chamado `machu-picchu-guide.txt` (ou o nome que preferir, mas lembre-se de atualizar a vari√°vel `FILE_PATH` em `index.py`).
2.  Cole todo o conte√∫do do seu guia tur√≠stico neste arquivo.

### 5\. Execu√ß√£o

O processo √© feito em duas etapas:

**Passo 1: Indexar o Conte√∫do**
Execute o script `index.py` para processar seu arquivo de texto e criar o banco de dados vetorial.

```bash
python index.py
```

Isso criar√° uma pasta chamada `meu_faiss_index` no seu diret√≥rio. Deve ser executado apenas uma vez, desde que o guia n√£o seja modificado ap√≥s a execu√ß√£o.

**Passo 2: Iniciar o Chatbot**
Agora voc√™ pode conversar com o bot executando o `main.py`.

```bash
python main.py
```

## üõ†Ô∏è Customiza√ß√£o

  - **Mudar a Fonte de Conhecimento:** Simplesmente altere o conte√∫do do arquivo `.txt` e execute `python index.py` novamente para reindexar.
  - **Mudar os Modelos:** Voc√™ pode experimentar outros modelos alterando as vari√°veis `LLM_MODEL` e `EMBEDDING_MODEL` nos arquivos `.py`. Lembre-se de baixar os modelos correspondentes via Ollama ou garantir que a biblioteca correta esteja instalada.

## üíª Tecnologias Utilizadas

  - **Python**
  - **LangChain:** Framework para desenvolvimento de aplica√ß√µes com LLMs.
  - **Ollama:** Ferramenta para rodar LLMs localmente.
  - **FAISS:** Biblioteca para busca de similaridade eficiente e banco de dados vetorial.
  - **Hugging Face Sentence Transformers:** Para gerar os embeddings de texto.
  - **PyTorch:** Biblioteca de machine learning.

-----
